{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import replace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_iris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature, threshold, left_node, right_node, value, probas):\n",
    "        self._feature = feature\n",
    "        self._threshold = threshold\n",
    "        self._left_node = left_node\n",
    "        self._right_node = right_node\n",
    "        self._value = value\n",
    "        self._probas = probas\n",
    "\n",
    "    @property\n",
    "    def feature(self):\n",
    "        return self._feature\n",
    "\n",
    "    @property\n",
    "    def threshold(self):\n",
    "        return self._threshold\n",
    "\n",
    "    @property\n",
    "    def left_node(self):\n",
    "        return self._left_node\n",
    "\n",
    "    @property\n",
    "    def right_node(self):\n",
    "        return self._right_node\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "    @property\n",
    "    def probas(self):\n",
    "        return self._probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    DEFAULT_MAX_DEPTH = 3\n",
    "    CRITERIONS = ('gini', 'entropy')\n",
    "    DEFAULT_CRITERION = CRITERIONS[0]\n",
    "    MIN_SAMPLES_SPLIT = 2\n",
    "    DEFAULT_COLUMNS_COUNT='all'\n",
    "\n",
    "    def __init__(self, columns_count=DEFAULT_COLUMNS_COUNT, max_depth=DEFAULT_MAX_DEPTH, min_samples_split=MIN_SAMPLES_SPLIT, criterion=DEFAULT_CRITERION):\n",
    "        \"\"\"\n",
    "        :param max_depth: The maximum depth of the tree.\n",
    "        :param min_features: If there are less than `min_features` features in the node, do not grow the tree. If none, ignore the value.\n",
    "        :param criterion: The criterion for building the tree. Can be either 'gini' or 'entropy'\n",
    "        \"\"\"\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_split = min_samples_split\n",
    "        self._criterion = criterion\n",
    "        self._columns_count = columns_count\n",
    "\n",
    "        if self._criterion not in self.CRITERIONS:\n",
    "            possible_criterions = ', '.join(self.CRITERIONS)\n",
    "            raise AttributeError(f'`criterion` should be one of the following: {possible_criterions}')\n",
    "\n",
    "        self.base_node = None  # initialy None, grow the tree (using Nodes) when fitting\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the classifier.\n",
    "        \"\"\"\n",
    "        self._x_train: pd.DataFrame = x_train\n",
    "        self._y_train: pd.Series = y_train\n",
    "        \n",
    "        self.classes = list(set(self._y_train))\n",
    "\n",
    "        self.base_node = self._grow_tree(self._x_train, self._y_train)\n",
    "\n",
    "    def _criterion_entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the entropy criterion\n",
    "        TODO: implement\n",
    "        \"\"\"\n",
    "\n",
    "    def _criterion_gini(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the Gini criterion\n",
    "        TODO: implement\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        p_mk = counts/y.shape[0]\n",
    "        return (p_mk*(1- p_mk)).sum()\n",
    "\n",
    "    def _criterion_f(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the criterion using `self._criterion`\n",
    "        Call the `_criterion_{criterion}` method.\n",
    "        \"\"\"\n",
    "        return getattr(self, f'_criterion_{self._criterion}')(y)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    def _grow_tree(self, X: pd.DataFrame, y, depth=0):\n",
    "        \"\"\"\n",
    "        Grow the tree.\n",
    "        TODO: implement\n",
    "        Hint: use recursion\n",
    "        \"\"\"\n",
    "        if self._columns_count == 'all':\n",
    "            self._columns_count = self._x_train.shape[1]\n",
    "        columns = np.random.choice(X.columns.values, self._columns_count, replace=False)\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probas = {}\n",
    "        for i,cls in enumerate(classes):\n",
    "            probas[cls] = counts[i]/y.shape[0]\n",
    "        for cls in self.classes:\n",
    "            probas.setdefault(cls, 0)\n",
    "        probas_sorted = sorted(probas.items())\n",
    "        probas_list = [value[1] for value in probas_sorted]\n",
    "        \n",
    "        if depth >= self._max_depth or X.shape[0] < self._min_samples_split:\n",
    "            node = Node(None, None, None, None, value=classes[np.argmax(counts)], probas=probas_list)\n",
    "        else:   \n",
    "            gini_min = 1\n",
    "            node_feature=None\n",
    "            node_threshold=None\n",
    "            for feature in columns:\n",
    "                feature_values = X[feature]\n",
    "                feature_values_su = np.unique(feature_values)\n",
    "                for threshold in feature_values_su[:-1]:\n",
    "                    y_left, y_right = y[X[feature] <= threshold], y[X[feature] > threshold]\n",
    "                    w_l, w_r = np.array([y_left.shape[0], y_right.shape[0]]) / y.shape[0]\n",
    "                    gini_lr =  self._criterion_f(y_left)*w_l + self._criterion_f(y_right)*w_r\n",
    "                    if gini_lr < gini_min:\n",
    "                        gini_min = gini_lr\n",
    "                        node_threshold = threshold\n",
    "                        node_feature = feature\n",
    "            \n",
    "            if node_feature:\n",
    "                X_left, X_right = X[X[node_feature] <= node_threshold], X[X[node_feature] > node_threshold]\n",
    "                y_left, y_right = y[X[node_feature] <= node_threshold], y[X[node_feature] > node_threshold]\n",
    "\n",
    "                left_node = self._grow_tree(X_left, y_left, depth+1)\n",
    "                right_node = self._grow_tree(X_right, y_right, depth+1)\n",
    "\n",
    "                node = Node(node_feature, node_threshold, left_node, right_node, value=classes[np.argmax(counts)], probas=probas_list)\n",
    "            else:\n",
    "                node = Node(None, None, None, None, value=classes[np.argmax(counts)], probas=probas_list)\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def tree_value(self, node: Node, x, value_type='value'):\n",
    "        if value_type not in ['value', 'probas']:\n",
    "            raise ValueError\n",
    "        feature = node.feature\n",
    "        threshold = node.threshold\n",
    "        if feature is None:\n",
    "            if value_type=='value':\n",
    "                return node.value\n",
    "            elif value_type=='probas':\n",
    "                return node.probas\n",
    "        if x[feature] > threshold:\n",
    "            next_node = node.right_node\n",
    "        else:\n",
    "            next_node = node.left_node\n",
    "\n",
    "        return self.tree_value(next_node, x, value_type)\n",
    "        \n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        Predict which class is each data in x\n",
    "        :param x: features matrix\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for i, row in x_test.iterrows():\n",
    "            y_pred.append(self.tree_value(self.base_node, row))\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"\n",
    "        Predict the probability, that x is of class 1.\n",
    "        TODO: implement\n",
    "        \"\"\"\n",
    "        y_probas = []\n",
    "        for i, row in x.iterrows():\n",
    "            y_probas.append(self.tree_value(self.base_node, row, value_type='probas'))\n",
    "        return np.array(y_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier:\n",
    "    DEFAULT_TREES_COUNT = 100\n",
    "    DEFAULT_MAX_DEPTH = 3\n",
    "    CRITERIONS = ('gini', 'entropy')\n",
    "    DEFAULT_CRITERION = CRITERIONS[0]\n",
    "    MIN_SAMPLES_SPLIT = 2\n",
    "    DEFAULT_COLUMNS_COUNT=1\n",
    "\n",
    "    def __init__(self, n_estimators=DEFAULT_TREES_COUNT, columns_count=DEFAULT_COLUMNS_COUNT, max_depth=DEFAULT_MAX_DEPTH, min_samples_split=MIN_SAMPLES_SPLIT, criterion=DEFAULT_CRITERION):\n",
    "        \"\"\"\n",
    "        :param n_estimators: Count of trees.\n",
    "        \"\"\"\n",
    "        self._n_estimators = n_estimators\n",
    "        self._columns_count = columns_count\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_split = min_samples_split\n",
    "        self._criterion = criterion\n",
    "\n",
    "        self._trees: list[DecisionTreeClassifier] = []\n",
    "\n",
    "        if self._criterion not in self.CRITERIONS:\n",
    "            possible_criterions = ', '.join(self.CRITERIONS)\n",
    "            raise AttributeError(f'`criterion` should be one of the following: {possible_criterions}')\n",
    "    \n",
    "    def fit(self, x_train: pd.DataFrame, y_train: pd.Series):\n",
    "        self._x_train: pd.DataFrame = x_train\n",
    "        self._y_train: pd.Series = y_train\n",
    "        self.classes = np.unique(self._y_train)\n",
    "\n",
    "        for _ in range(self._n_estimators):\n",
    "            indexes = np.random.choice(self._x_train.index, self._x_train.shape[0], replace=True)\n",
    "            x_i = self._x_train.loc[indexes]\n",
    "            y_i = self._y_train.loc[indexes]\n",
    "            clf = DecisionTreeClassifier(\n",
    "                columns_count=self._columns_count,\n",
    "                max_depth=self._max_depth,\n",
    "                min_samples_split=self._min_samples_split,\n",
    "                criterion=self._criterion\n",
    "            )\n",
    "            clf.fit(x_i, y_i)\n",
    "            self._trees.append(clf)\n",
    "    \n",
    "    def predict_trees(self, x_test):\n",
    "        all_predictions = []\n",
    "        tree_predictions = []\n",
    "        for tree in self._trees:\n",
    "            tree_predictions.append(tree.predict(x_test))\n",
    "        all_predictions = np.array(tree_predictions).T\n",
    "        return all_predictions\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        all_predictions = self.predict_trees(x_test)\n",
    "        return np.array(pd.DataFrame(all_predictions).mode(axis=1)[0])\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 2 0 2 0 1 1 1 1 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n",
      "[2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0]\n",
      "None\n",
      "Train f1 score: 0.9584423580113898\n",
      "Test f1 score: 0.957351290684624\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = pd.DataFrame(iris['data'], columns=iris['feature_names']), pd.Series(iris['target'])\n",
    "\n",
    "\n",
    "X_resampled = X.iloc[np.random.choice(X.index, X.shape[0])]\n",
    "    \n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=50, max_depth=3)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.predict(X_test))\n",
    "print(np.array(y_test))\n",
    "print(clf.predict_proba(X_test))\n",
    "\n",
    "print('Train f1 score:', f1_score(y_train, clf.predict(X_train), average='macro'))\n",
    "print('Test f1 score:', f1_score(y_test, clf.predict(X_test), average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29d378c6f9f9303028c651f034ce8b915ddf31b448ad445ead3b2b3c8d60aef3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
