{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature, threshold, left_node, right_node, value, probas):\n",
    "        self._feature = feature\n",
    "        self._threshold = threshold\n",
    "        self._left_node = left_node\n",
    "        self._right_node = right_node\n",
    "        self._value = value\n",
    "        self._probas = probas\n",
    "\n",
    "    @property\n",
    "    def feature(self):\n",
    "        return self._feature\n",
    "\n",
    "    @property\n",
    "    def threshold(self):\n",
    "        return self._threshold\n",
    "\n",
    "    @property\n",
    "    def left_node(self):\n",
    "        return self._left_node\n",
    "\n",
    "    @property\n",
    "    def right_node(self):\n",
    "        return self._right_node\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "    @property\n",
    "    def probas(self):\n",
    "        return self._probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier:\n",
    "    DEFAULT_MAX_DEPTH = 3\n",
    "    CRITERIONS = ('gini', 'entropy')\n",
    "    DEFAULT_CRITERION = CRITERIONS[0]\n",
    "    MIN_SAMPLES_SPLIT = 2\n",
    "\n",
    "    def __init__(self, max_depth=DEFAULT_MAX_DEPTH, min_samples_split=MIN_SAMPLES_SPLIT, criterion=DEFAULT_CRITERION):\n",
    "        \"\"\"\n",
    "        :param max_depth: The maximum depth of the tree.\n",
    "        :param min_features: If there are less than `min_features` features in the node, do not grow the tree. If none, ignore the value.\n",
    "        :param criterion: The criterion for building the tree. Can be either 'gini' or 'entropy'\n",
    "        \"\"\"\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_split = min_samples_split\n",
    "        self._criterion = criterion\n",
    "\n",
    "        if self._criterion not in self.CRITERIONS:\n",
    "            possible_criterions = ', '.join(self.CRITERIONS)\n",
    "            raise AttributeError(f'`criterion` should be one of the following: {possible_criterions}')\n",
    "\n",
    "        self._tree = None  # initialy None, grow the tree (using Nodes) when fitting\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the classifier.\n",
    "        \"\"\"\n",
    "        self._x_train: pd.DataFrame = x_train\n",
    "        self._y_train: pd.Series = y_train\n",
    "        \n",
    "        self.classes = list(set(self._y_train))\n",
    "\n",
    "        self.base_node = self._grow_tree(self._x_train, self._y_train)\n",
    "\n",
    "    def _criterion_entropy(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the entropy criterion\n",
    "        \"\"\"\n",
    "\n",
    "    def _criterion_gini(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the Gini criterion\n",
    "        \"\"\"\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        p_mk = counts/y.shape[0]\n",
    "        return (p_mk*(1- p_mk)).sum()\n",
    "\n",
    "    def _criterion_f(self, y):\n",
    "        \"\"\"\n",
    "        Calculate the criterion using `self._criterion`\n",
    "        Call the `_criterion_{criterion}` method.\n",
    "        \"\"\"\n",
    "        return getattr(self, f'_criterion_{self._criterion}')(y)\n",
    "    \n",
    "    \n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        \"\"\"\n",
    "        Grow the tree.\n",
    "        \"\"\"\n",
    "        classes, counts = np.unique(y, return_counts=True)\n",
    "        probas = {}\n",
    "        for i,cls in enumerate(classes):\n",
    "            probas[cls] = counts[i]/y.shape[0]\n",
    "        for cls in self.classes:\n",
    "            probas.setdefault(cls, 0)\n",
    "        probas_sorted = sorted(probas.items())\n",
    "        probas_list = [value[1] for value in probas_sorted]\n",
    "        \n",
    "        if depth >= self._max_depth or X.shape[0] < self._min_samples_split:\n",
    "            node = Node(None, None, None, None, value=classes[np.argmax(counts)], probas=probas_list)\n",
    "        else:   \n",
    "            gini_min = 1\n",
    "            node_feature=None\n",
    "            node_threshold=None\n",
    "            for feature in self._x_train.columns:\n",
    "                feature_values = X[feature]\n",
    "                feature_values_su = np.unique(feature_values)\n",
    "                for threshold in feature_values_su[:-1]:\n",
    "                    y_left, y_right = y[X[feature] <= threshold], y[X[feature] > threshold]\n",
    "                    w_l, w_r = np.array([y_left.shape[0], y_right.shape[0]]) / y.shape[0]\n",
    "                    gini_lr =  self._criterion_f(y_left)*w_l + self._criterion_f(y_right)*w_r\n",
    "                    if gini_lr < gini_min:\n",
    "                        gini_min = gini_lr\n",
    "                        node_threshold = threshold\n",
    "                        node_feature = feature\n",
    "            \n",
    "            if node_feature:\n",
    "                X_left, X_right = X[X[node_feature] <= node_threshold], X[X[node_feature] > node_threshold]\n",
    "                y_left, y_right = y[X[node_feature] <= node_threshold], y[X[node_feature] > node_threshold]\n",
    "\n",
    "                left_node = self._grow_tree(X_left, y_left, depth+1)\n",
    "                right_node = self._grow_tree(X_right, y_right, depth+1)\n",
    "\n",
    "                node = Node(node_feature, node_threshold, left_node, right_node, value=classes[np.argmax(counts)], probas=probas_list)\n",
    "            else:\n",
    "                node = Node(None, None, None, None, value=classes[np.argmax(counts)], probas=probas_list)\n",
    "\n",
    "        return node\n",
    "    \n",
    "    def tree_value(self, node: Node, x, value_type='value'):\n",
    "        if value_type not in ['value', 'probas']:\n",
    "            raise ValueError\n",
    "        feature = node.feature\n",
    "        threshold = node.threshold\n",
    "        if feature is None:\n",
    "            if value_type=='value':\n",
    "                return node.value\n",
    "            elif value_type=='probas':\n",
    "                return node.probas\n",
    "        if x[feature] > threshold:\n",
    "            next_node = node.right_node\n",
    "        else:\n",
    "            next_node = node.left_node\n",
    "\n",
    "        return self.tree_value(next_node, x, value_type)\n",
    "        \n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        Predict which class is each data in x\n",
    "        :param x: features matrix\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for i, row in x_test.iterrows():\n",
    "            y_pred.append(self.tree_value(self.base_node, row))\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        \"\"\"\n",
    "        Predict the probability, that x is of class 1.\n",
    "        \"\"\"\n",
    "        y_probas = []\n",
    "        for i, row in x.iterrows():\n",
    "            y_probas.append(self.tree_value(self.base_node, row, value_type='probas'))\n",
    "        return np.array(y_probas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train f1 score: 0.9750654148068341\n",
      "Test f1 score: 0.9018808777429467\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = pd.DataFrame(iris['data'], columns=iris['feature_names']), iris['target']\n",
    "clf = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print('Train f1 score:', f1_score(y_train, clf.predict(X_train), average='macro'))\n",
    "print('Test f1 score:', f1_score(y_test, clf.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29d378c6f9f9303028c651f034ce8b915ddf31b448ad445ead3b2b3c8d60aef3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
